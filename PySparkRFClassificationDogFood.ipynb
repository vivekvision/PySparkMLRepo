{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySparkRFClassificationDogFood.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJdhB938EgTLuKsbQOrNCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekvision/PySparkMLRepo/blob/main/PySparkRFClassificationDogFood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "521xvQ2Rya0C",
        "outputId": "7e842785-d44d-4640-e76d-dab20a79940f"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 38 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 64.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=4f1df49de5361db53b04f5151baa4a1a79dc28f6ea72fce2af575b611f4afeec\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAEH3nFtyxl-"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .appName(\"testApp\")\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IyF3LtKzY-m"
      },
      "source": [
        "dog food company to try : predict why some batches of dog food are spoiling much quicker than intended\n",
        "\n",
        "the amounts of the five preservative chemicals used can vary a lot, but which is the chemical that has the strongest effect? \n",
        "\n",
        "While manufactoring first mixes up a batch of preservative that contains 4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. \n",
        "\n",
        "Find out which one out of A,B,C, or D preservatives is causing the problem\n",
        "\n",
        "Use RF to find out which parameter had the most predicitive power, thus finding out which chemical causes the early spoiling! \n",
        "\n",
        "create a model and then find out how you can decide which chemical is the problem!\n",
        "\n",
        "Pres_A : Percentage of preservative A in the mix\n",
        "\n",
        "Pres_B : Percentage of preservative B in the mix\n",
        "\n",
        "Pres_C : Percentage of preservative C in the mix\n",
        "\n",
        "Pres_D : Percentage of preservative D in the mix\n",
        "\n",
        "Spoiled: Label indicating whether or not the dog food batch was spoiled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCrnGVhqzdJN"
      },
      "source": [
        "data = spark.read.csv('dog_food.csv', inferSchema = True, header = True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIY_VBWC0MfF",
        "outputId": "e11662de-7e2c-478f-d16a-7851d0a7c08b"
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- A: integer (nullable = true)\n",
            " |-- B: integer (nullable = true)\n",
            " |-- C: double (nullable = true)\n",
            " |-- D: integer (nullable = true)\n",
            " |-- Spoiled: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK0mLQei0dl0",
        "outputId": "26d7dddd-0406-4b27-d27e-0ea803efd820"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(A=4, B=2, C=12.0, D=3, Spoiled=1.0),\n",
              " Row(A=5, B=6, C=12.0, D=7, Spoiled=1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvAApmon0ibM"
      },
      "source": [
        "# Import VectorAssembler and Vectors\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JuXMeuq0lP8"
      },
      "source": [
        "assembler = VectorAssembler(inputCols=['A', 'B', 'C', 'D'], outputCol=\"features\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgO71UV60og1"
      },
      "source": [
        "output = assembler.transform(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCDf_Vtu0toV"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIHYAJlM5lFH"
      },
      "source": [
        "rfc = RandomForestClassifier(labelCol='Spoiled', featuresCol='features')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCOllwOa5szk",
        "outputId": "50c7ef58-1724-4e3d-8422-145e9e9d75a4"
      },
      "source": [
        "output.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- A: integer (nullable = true)\n",
            " |-- B: integer (nullable = true)\n",
            " |-- C: double (nullable = true)\n",
            " |-- D: integer (nullable = true)\n",
            " |-- Spoiled: double (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0X7Pbcr5x-k"
      },
      "source": [
        "final_data = output.select('features','Spoiled') # only these two required by model to fit "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZGLjPWO53CU"
      },
      "source": [
        "rfc_model = rfc.fit(final_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UQQ1Jci_i8g"
      },
      "source": [
        "many machine learning models produce some sort of coefficient value for each feature involved, indicating their importance or predictive power \n",
        "\n",
        "Tree classifiers have a .featureImportance attribute available \n",
        "\n",
        "It can be used to check which feature (preservative) is causing the spoilage "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-ve8TtU7qGE",
        "outputId": "d37b8aa3-b150-4b8e-a1b4-edf6c2fdbffd"
      },
      "source": [
        "rfc_model.featureImportances"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(4, {0: 0.0134, 1: 0.0101, 2: 0.9527, 3: 0.0238})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CzfRXMcAJrF"
      },
      "source": [
        "first entry of SpareVector is number of features used \n",
        "second entry is dictionary of feature number & the importance \n",
        "\n",
        "feature index 2 which is C is most important \n"
      ]
    }
  ]
}